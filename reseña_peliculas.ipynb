{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyOx6PfM5eH3Q7+oRNR/aohR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanAcevedo08/DeepLearning/blob/main/rese%C3%B1a_peliculas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Instalación e importación de librerías y comprobamos versiones"
      ],
      "metadata": {
        "id": "kBaDO0LY4eYj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXUQj6604Evc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch==2.2.0\n",
        "!pip install torchtext==0.17.2 torchdata==0.7.1 portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import torch, torchtext, torchdata #Librerías a utilizar"
      ],
      "metadata": {
        "id": "hfs1CJqt5bdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comprbamos las versiones\n",
        "print(f'Version torch: {torch.__version__}')\n",
        "print(f'Version torchtext: {torchtext.__version__}')\n",
        "print(f'Version torchdata: {torchdata.__version__}')"
      ],
      "metadata": {
        "id": "I6jCdBrK5kuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB"
      ],
      "metadata": {
        "id": "FEsd-jNZ96po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Importamos los datos que necesitamos procesarlos(Tokenizacion y vocabulario)"
      ],
      "metadata": {
        "id": "XPFj51tT-UyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "¿Que es tokenizar y que es un vocabulario?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Tokenizar: Es el proceso mediante se dividen palabras dentro de una oración. Ejemplo: 'Hi how are you?'  el tokenizador se encarga de agarrar los espacios entre la oración para poder dividirlos y que nos de algo como: 'hi', 'how', 'are', 'you'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> Vocabulario: En este se le otorga un numero a cada token , como vimos anterior un token es una palabra de una oración , el vocabulario le otorga un identificador para poder determinar palabras unicas, Ejemplo: {'hi': 0} identificador 0\n",
        "\n"
      ],
      "metadata": {
        "id": "CcbATeQwBR3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizacion\n",
        "train_iter = iter(IMDB(split=('train')))\n",
        "next(train_iter) #Visualizar un ejemplo"
      ],
      "metadata": {
        "id": "KHsq06fB-D_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importar librerias para tokenizador y vocabulario\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "#Creamos el tokenizador\n",
        "tokenizador = get_tokenizer('basic_english') #Definimos el idioma de los datos\n",
        "\n",
        "#Instanciamos los datos de entrenamiento para que realice el vocabulario\n",
        "train_iter = IMDB(split=('train'))\n",
        "\n",
        "#Creamos una función para que le aplique el tokenizador a cada uno de los comentarios\n",
        "def tokenizar_comentarios(data):\n",
        "  for _, text in data:\n",
        "    yield tokenizador(text)\n",
        "\n",
        "#Creamos el vocabulario\n",
        "vocab = build_vocab_from_iterator(tokenizar_comentarios(train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "#Probamos el vocabulario\n",
        "texto = 'The fate of the human is be safe in this world'\n",
        "\n",
        "#Texto pasado por el vocab\n",
        "print(vocab(tokenizador(texto)))"
      ],
      "metadata": {
        "id": "8IQSw6W7-lCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 Realizar funciones automatizadoras"
      ],
      "metadata": {
        "id": "mkO7vqlOCLUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Funciones lambada\n",
        "\n",
        "#Convertidora a vocabulario\n",
        "convertidor_vocab = lambda x: vocab(tokenizador(x))\n",
        "\n",
        "#Ajustador clase | Este se da , debido a que la función de costo ya que las salidas son [0...nclases] y la funcion de costo compara con clase real [1...n] hay un indice menos entonces hay que bajarle 1\n",
        "ajuste_numerico = lambda x: int(x) - 1"
      ],
      "metadata": {
        "id": "xgWKrybrBOh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Función collate"
      ],
      "metadata": {
        "id": "vu4yAIYCFW-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Cuando manejamos grandes volumnes de datos durante muchas veces es necesario tener un data loader que divida nuestros dato enbatches para que pase batches en vez de todos los datos enteros entonces en estos dataloaders cuando pasamos nuestros datos es mejor para el modelo que reciba no solo los datos ya procesados sino ademas que los reciba en un densor de una dimension par que sea mas facil realizar este proceso para lo que vamos a necesitar el tensor con tensores, el tensor con labels reales y un offsets ya que como lo que vamos a hacer es concatenar tensores en uno solo , el offsets indicará donde va inciar la oracion"
      ],
      "metadata": {
        "id": "dQEVaWwXFdKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fijamos dispotivo que van a tener los tensores\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Es muy importante ya que los tensores que creemos tienen que permanecer en el mismo tipo de dato y dispositivo\n",
        "\n",
        "#Creación de la función\n",
        "\n",
        "def collate_(batch):\n",
        "  \"\"\"\n",
        "  Parametro: un lote de todos los datos para ser procesados\n",
        "  durante este proceso , separa el lote en texto y etiquetas para poder procesar tanto texto como etiqueta agregando en una lista cada etiqueta y texto procesado y se establece que todos esten el mismo tipo de dato\n",
        "  etiquetas_: es un tensor que contiene otro tensor con las tiquetas en enteros\n",
        "  indicadores_: contiene un tensor con las sumass de las longiudes de los textos para indicar donde va iniciar cada frase\n",
        "  textos_: tiene un tensor que contiene una concatenacion de  enteros donde cada entero representa una palabra del texto\n",
        "\n",
        "  return: 3 tensores en el mismo dispotivio y mismo tipo de tensor\n",
        "  \"\"\"\n",
        "  etiquetas_ = []\n",
        "  indicadores_ = []\n",
        "  textos_ = []\n",
        "\n",
        "  for (etiqueta_ , texto_) in batch:\n",
        "    etiquetas_.append(ajuste_numerico(etiqueta_))\n",
        "    texto_torch = torch.tensor(convertidor_vocab(texto_), dtype=torch.int64)\n",
        "    textos_.append(texto_torch)\n",
        "    indicadores_.append(texto_torch.size(0))\n",
        "\n",
        "  etiquetas_ = torch.tensor(etiquetas_, dtype=torch.int64)\n",
        "  indicadores_ = torch.tensor([0] + torch.tensor(indicadores_[:-1]).cumsum(dim=0).tolist(), dtype=torch.int64)\n",
        "\n",
        "  textos_ = torch.cat(textos_)\n",
        "\n",
        "  return etiquetas_.to(device), indicadores_.to(device) , textos_.to(device)"
      ],
      "metadata": {
        "id": "tam9WxrgFWM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Creación de modelo clasificador de texto"
      ],
      "metadata": {
        "id": "BJ7SYmm4RJo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este modelo tenemos 3 diferentes entradas donde dos de ellas nos van a servir para el embedding , el embedding se encarga de utilizar el vocabulario para crear vectores de densidad que nos puedan representar similitudes entre palabras para esto indico la cantidad de palabras en vocabulario y el tamaño de los vectores a realizar luego de eso tenemos un atributo de normalizacion que se va encargar de estandarizar los valroes a las mismas escalas usando la formula conocida x - u / o , de esa manera evita que el modelo se confunda con valores muy altos y finalmente una funcion de decisión que se encarga de prpoyectar cada una de las entradas a la cantidad de clase que tenemos para definir sus valores y tomar la decisión\n",
        "\n",
        "***Forward:***\n",
        "\n",
        "En este empezamos con el embedgin este es un bag que se va encargar de ademas de sus atributos fijos tiene atributos dinamicos , ya que estos son para cuando tengo este tipo de tensores concatenados entonces me toca indicar de donde a donde va realizar los embeding , luefo de realizar los embeds por cada oracion dentro del tensor se encarga de promediar , sumar o agarrar el valor maximo de los embds para definir un solo embd por oracion y finalmente normalizarlo, luego de eso lo pasa a una fucnion de activacion que va determinar su valor para pasarlo a conclusion de que clase es"
      ],
      "metadata": {
        "id": "HTlej9tpT2v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTextClassifier(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_clases):\n",
        "    super(ModelTextClassifier, self).__init__()\n",
        "\n",
        "    self.embd = torch.nn.EmbeddingBag(vocab_size, embed_dim)\n",
        "    self.norm = torch.nn.BatchNorm1d(embed_dim)\n",
        "    self.fc = torch.nn.Linear(embed_dim, num_clases)\n",
        "\n",
        "  def forward(self, text, offsets):\n",
        "    embed = self.embd(text, offsets)\n",
        "    norm = self.norm(embed)\n",
        "    activacion = torch.nn.functional.relu(norm)\n",
        "    return self.fc(activacion)"
      ],
      "metadata": {
        "id": "g_B5xpCxP-ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisar estructura, parametros y clases del modelo\n",
        "temp_iter = IMDB(split='test')\n",
        "n_clases = len(set([label for (label, text) in temp_iter]))\n",
        "modelo_clf = ModelTextClassifier(len(vocab), 200, n_clases).to(device) #Poner el modelo en el mismo dispotivo de los tensores\n",
        "\n",
        "#Función para revisar catnidad de parametros entrenables\n",
        "def parametros_entrenables(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Cantidad de clases {n_clases} ')\n",
        "print(f'Estructura del modelo:\\n {modelo_clf}')\n",
        "print(f'Cantidad de parametros a entrenar {parametros_entrenables(modelo_clf):,}')"
      ],
      "metadata": {
        "id": "Dh5gMv7CV-hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 Función entrenamiento  "
      ],
      "metadata": {
        "id": "3Xau5frzVVbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear una funcion de entrenamiento para el modelo\n",
        "\n",
        "def funcion_entrenamiento(modelo, dataloader):\n",
        "  #Activar modeo de entrenamiento\n",
        "  modelo.train()\n",
        "  #Creación de variables\n",
        "  precision_ = 0\n",
        "  perdida_ = 0\n",
        "  etiquetas_ = 0\n",
        "\n",
        "  for (etiqueta , indicador , texto ) in dataloader:\n",
        "    #Limpiar gradientes\n",
        "    optimizador.zero_grad()\n",
        "    #Realizar una preddición\n",
        "    prediccion = modelo(texto, indicador)\n",
        "    #Calcular perdida\n",
        "    perdida = criterio(prediccion, etiqueta)\n",
        "    #Calcular aciertos\n",
        "    aciertos = (prediccion.argmax(1) == etiqueta).sum()\n",
        "    #Realizar backward (calculo de gradientes)\n",
        "    perdida.backward()\n",
        "    #Cortar los parametros a 0.1 para que no sea un gradiente muy grande\n",
        "    torch.nn.utils.clip_grad_norm_(modelo.parameters(), 0.1)\n",
        "    #Ajustar los pesos\n",
        "    optimizador.step()\n",
        "    #Ajustar las variables de información\n",
        "    precision_ += aciertos.item()\n",
        "    perdida_ += perdida.item()\n",
        "    etiquetas_ += etiqueta.size(0)\n",
        "\n",
        "  precision_promedio = precision_ / etiquetas_\n",
        "  perdida_promedio = perdida_ / etiquetas_\n",
        "\n",
        "  return precision_promedio, perdida_promedio"
      ],
      "metadata": {
        "id": "4FkZadErVJMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Funcion de evaluacion"
      ],
      "metadata": {
        "id": "XUUfuRn5gwOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def funcion_evaluacion(modelo, dataloader):\n",
        "  #Ajusta en modo evaluacion\n",
        "  modelo.eval()\n",
        "  #Crear variables para metricas\n",
        "  precision_ = 0\n",
        "  perdidas_ = 0\n",
        "  etiquetas_ = 0\n",
        "\n",
        "  #Retirar el gradiente para realizar evaluaciones sin gastar memoria\n",
        "  with torch.no_grad():\n",
        "    for i, (etiqueta_ , indicadores_, textos_) in enumerate(dataloader):\n",
        "      #Realizar preddicion con los datos de validacion\n",
        "      prediccion = modelo(textos_, indicadores_)\n",
        "      #Consultar perdida\n",
        "      perdida = criterio(prediccion, etiqueta_)\n",
        "      #Crear precision\n",
        "      precision = (prediccion.argmax(1) == etiqueta_).sum()\n",
        "\n",
        "      #Ajustar variaables - metricas\n",
        "      precision_ += precision.item()\n",
        "      perdidas_ += perdida.item()\n",
        "      etiquetas_ += etiqueta_.size(0)\n",
        "\n",
        "  #Calcular los promedios\n",
        "  precision_promedio = precision_ / etiquetas_\n",
        "  perdida_promedio = perdidas_ / etiquetas_\n",
        "\n",
        "\n",
        "  return precision_promedio, perdida_promedio"
      ],
      "metadata": {
        "id": "5M-LFOEyguOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Creacion de funcion de perdida, optimzador, separacion de datos y dataloaders"
      ],
      "metadata": {
        "id": "bvhgk1cWk5Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyper Parametros\n",
        "epocas = 10\n",
        "lotes = 64\n",
        "lr = 5e-3\n",
        "momentum = 0.9\n",
        "#Funcion de perdida\n",
        "criterio = torch.nn.CrossEntropyLoss()\n",
        "#Optimzador\n",
        "optimizador = torch.optim.SGD(modelo_clf.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "frzjhOuFkrap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Cargar solo el split de test que tiene ambas clases , ya que train no tiene\n",
        "datos_completos = iter(IMDB(split='test'))\n",
        "datos_completos = to_map_style_dataset(datos_completos)\n",
        "\n",
        "# Dividir en: 76% entrenamiento, 19% validación, 5% prueba\n",
        "total = len(datos_completos)\n",
        "train_size = int(0.76 * total)\n",
        "val_size = int(0.19 * total)\n",
        "test_size = total - train_size - val_size\n",
        "\n",
        "separacion_entrenamiento, separacion_validacion, separacion_prueba = random_split(\n",
        "    datos_completos,\n",
        "    lengths=[train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# Crear dataloaders\n",
        "dataloader_entrenamiento = DataLoader(separacion_entrenamiento, lotes, shuffle=True, collate_fn=collate_)\n",
        "dataloader_valdiacion = DataLoader(separacion_validacion, lotes, shuffle=True, collate_fn=collate_)\n",
        "dataloader_prueba = DataLoader(separacion_prueba, lotes, shuffle=True, collate_fn=collate_)"
      ],
      "metadata": {
        "id": "7SZIgUORnckk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Realizar entrenamiento y prueba\n"
      ],
      "metadata": {
        "id": "AKqKnOwJsscw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear una variable que tome el mejor promeedio de validaicon de perdida\n",
        "mejor_perdida_validacion = float('inf')\n",
        "\n",
        "#Realizar entrenamiento\n",
        "for epoca in range(1, epocas + 1 ):\n",
        "  #Empezar a entrenar y recibir informacion\n",
        "  precision_promedio_et, perdida_promedio_et = funcion_entrenamiento(modelo_clf, dataloader_entrenamiento)\n",
        "  #Empear a validar y recibir informacion\n",
        "  precision_promedio_ev, perdida_promedio_ev = funcion_evaluacion(modelo_clf, dataloader_valdiacion)\n",
        "\n",
        "  print(f'Época {epoca}/{epocas}:')\n",
        "  print(f'  Train -> Pérdida: {perdida_promedio_et:.4f}, Precisión: {precision_promedio_et:.4f}')\n",
        "  print(f'  Val   -> Pérdida: {perdida_promedio_ev:.4f}, Precisión: {precision_promedio_ev:.4f}')\n",
        "\n",
        "  if perdida_promedio_ev < mejor_perdida_validacion:\n",
        "    mejor_perdida_validacion = perdida_promedio_ev\n",
        "    torch.save(modelo_clf.state_dict(), 'mejor_modelo_eval.pt')\n",
        "    print(f'MOdelo guardado')"
      ],
      "metadata": {
        "id": "dw0lp0XsrZyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_promedio_pb, perdida_promedio_pb = funcion_evaluacion(modelo_clf, dataloader_prueba)\n",
        "\n",
        "print(f'Precision_prueba: {precision_promedio_pb}')\n",
        "print(f'Perdida_prueba: {perdida_promedio_pb}')"
      ],
      "metadata": {
        "id": "Pe1DM7VJvLvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9 Realizar inferencia"
      ],
      "metadata": {
        "id": "2ovIWC8rMmSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mapeo de las clases a clasificar\n",
        "clases = ['neg', 'pos']\n",
        "#Realizar función de predicción con datos reales\n",
        "def prediccion(texto, modelo):\n",
        "  #Ajustar modo inferencia\n",
        "  with torch.inference_mode():\n",
        "    #Transformacion del texto\n",
        "    entrada = torch.tensor(convertidor_vocab(texto), device=device)\n",
        "    #Realiza prediccion\n",
        "    salida = modelo(entrada, torch.tensor([0] , device=device, dtype=torch.int64))\n",
        "\n",
        "    return salida.argmax(1).item()"
      ],
      "metadata": {
        "id": "3ACsyiykwXIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Crear funcion para probar ejemplos\n"
      ],
      "metadata": {
        "id": "pycEy8aiPDGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simular una base de datos falsa\n",
        "db_falsa = [[\n",
        "     # NEGATIVAS (0)\n",
        "    'The movie was boring and too long, I almost fell asleep.',\n",
        "    'Terrible customer service, I will never return.',\n",
        "    'The product broke after one use, very disappointing.',\n",
        "    'The food was cold and tasteless, not worth the money.',\n",
        "    'Worst experience ever, I regret buying this.'],\n",
        "\n",
        "    [# POSITIVAS (1)\n",
        "    'This movie was amazing, I loved every second of it!',\n",
        "    'The product exceeded my expectations, highly recommended.',\n",
        "    'Great service and friendly staff, will come back again.',\n",
        "    'Fantastic quality for the price, I am very satisfied.',\n",
        "    'An excellent experience, everything was perfect.']\n",
        "]\n",
        "\n",
        "#Realizar la función para probar ejemplos\n",
        "def pruebas(db, modelo, pred_fn):\n",
        "  aciertos = 0\n",
        "  espacio_muestral = 0\n",
        "  for i, v in enumerate(db):\n",
        "    print('*' * 200)\n",
        "    print(f'Entrando en sección reseñas {clases[i]}')\n",
        "    for texto in v:\n",
        "      valor = pred_fn(texto, modelo)\n",
        "      print(f'Texto: \\n {texto}')\n",
        "      print(f'Predicción {clases[valor]} | Clase a la que pertenece {clases[i]}')\n",
        "      if clases[valor] == clases[i]:\n",
        "        aciertos += 1\n",
        "      espacio_muestral += 1"
      ],
      "metadata": {
        "id": "4dfkTOyLO63X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Probar los ejemplos\n",
        "\n",
        "pruebas(db_falsa, modelo_clf, prediccion)"
      ],
      "metadata": {
        "id": "KPtgezOGjbYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11 cargar el modelo con mejor precision para val"
      ],
      "metadata": {
        "id": "rwFM_-wgqkTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/mejor_modelo_eval.pt') #Instanciamos un checkpoint"
      ],
      "metadata": {
        "id": "JaMf16Gaqphy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_iter = IMDB(split='test') #Crear el iterador\n",
        "#Variables necesarias para el modelo\n",
        "n_clases = len(set([label for (label, text) in temp_iter]))\n",
        "vocab_size = len(vocab)\n",
        "embd_dimn = 200\n",
        "#Crear el nuevo modelo y poner las clases\n",
        "# Versión simplificada para solo inferencia\n",
        "modelo_clfs_2 = ModelTextClassifier(len(vocab), 200, 2).to(device)\n",
        "modelo_clfs_2.load_state_dict(torch.load('/content/mejor_modelo_eval.pt'))\n",
        "modelo_clfs_2.eval()\n",
        "\n",
        "# Probar\n",
        "text = \"This film was a complete waste of time. The acting was terrible and the plot made no sense.\"\n",
        "value = prediccion(text, modelo_clfs_2)\n",
        "print(f'Clase real: neg | Clase predicha: {clases[value]}')"
      ],
      "metadata": {
        "id": "nvTiMsK1r_Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12 Cargar el modelo para subir a huggin face"
      ],
      "metadata": {
        "id": "EvXe31x3zEto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar los parametros del modelo\n",
        "modelo_pesos = modelo_clfs_2.state_dict()\n",
        "optimizador_dict = optimizador.state_dict()\n",
        "checkpoint_ = {\n",
        "    'Modelo': modelo_pesos,\n",
        "    'optimizador': optimizador_dict,\n",
        "    'epocas': epocas,\n",
        "    'learning_rate': lr,\n",
        "    'embd_size': embd_dimn,\n",
        "    'vocab_size': vocab_size,\n",
        "    'batch_size': lotes\n",
        "}\n",
        "\n",
        "torch.save(checkpoint_, \"./model_paraemetrs.pth\")"
      ],
      "metadata": {
        "id": "YoVrhT-ixW8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install hugginface_hub"
      ],
      "metadata": {
        "id": "DcUwBcNT0L2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "7x-nApAo0lKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "api.create_repo(repo_id=\"platzi/reviews_imbd-juan-acevedo\")"
      ],
      "metadata": {
        "id": "CKUqt67J02Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear repo para mi\n",
        "api.create_repo(repo_id=\"reviews_imbd\")"
      ],
      "metadata": {
        "id": "bTzF1gxw1uG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Subir el contenido al repo\n",
        "api.upload_file(path_or_fileobj='./model_paraemetrs.pth', path_in_repo='model_paraemetrs.pth', repo_id='platzi/reviews_imbd-juan-acevedo')\n",
        "api.upload_file(path_or_fileobj='./model_paraemetrs.pth', path_in_repo='model_paraemetrs.pth', repo_id='JuanAcevedo/reviews_imbd')"
      ],
      "metadata": {
        "id": "QsmHZ0rs2NCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}